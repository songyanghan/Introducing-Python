{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sys.path.append(glob.glob('/opt/carla-simulator/PythonAPI/carla/dist/carla-*3.7-%s.egg' % (\n",
    "        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])\n",
    "except IndexError:\n",
    "    pass\n",
    "\n",
    "import carla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from collections import deque\n",
    "from keras.applications.xception import Xception\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "#import keras.backend.tensorflow_backend as backend\n",
    "from threading import Thread\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_PREVIEW = False\n",
    "IM_WIDTH = 640\n",
    "IM_HEIGHT = 480\n",
    "SECONDS_PER_EPISODE = 10\n",
    "REPLAY_MEMORY_SIZE = 5_000   # 5,000\n",
    "MIN_REPLAY_MEMORY_SIZE = 1_000\n",
    "MINIBATCH_SIZE = 16\n",
    "PREDICTION_BATCH_SIZE = 1\n",
    "TRAINING_BATCH_SIZE = MINIBATCH_SIZE // 4\n",
    "UPDATE_TARGET_EVERY = 5\n",
    "MODEL_NAME = \"Xception\"\n",
    "\n",
    "MEMORY_FRACTION = 0.6\n",
    "MIN_REWARD = -200\n",
    "\n",
    "EPISODES = 100\n",
    "\n",
    "DISCOUNT = 0.99\n",
    "epsilon = 1\n",
    "EPSILON_DECAY = 0.95\n",
    "MIN_EPSILON = 0.001\n",
    "\n",
    "AGGREGATE_STATS_EVERY = 10\n",
    "\n",
    "\n",
    "# Own Tensorboard class\n",
    "class ModifiedTensorBoard(TensorBoard):\n",
    "\n",
    "    # Overriding init to set initial step and writer (we want one log file for all .fit() calls)\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.step = 1\n",
    "        self.writer = tf.contrib.summary.FileWriter(self.log_dir)\n",
    "\n",
    "    # Overriding this method to stop creating default log writer\n",
    "    def set_model(self, model):\n",
    "        pass\n",
    "\n",
    "    # Overrided, saves logs with our step number\n",
    "    # (otherwise every .fit() will start writing from 0th step)\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.update_stats(**logs)\n",
    "\n",
    "    # Overrided\n",
    "    # We train for one batch only, no need to save anything at epoch end\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        pass\n",
    "\n",
    "    # Overrided, so won't close writer\n",
    "    def on_train_end(self, _):\n",
    "        pass\n",
    "\n",
    "    # Custom method for saving own metrics\n",
    "    # Creates writer, writes custom metrics and closes writer\n",
    "    def update_stats(self, **stats):\n",
    "        self._write_logs(stats, self.step)\n",
    "\n",
    "\n",
    "class CarEnv:\n",
    "    SHOW_CAM = SHOW_PREVIEW\n",
    "    STEER_AMT = 1.0\n",
    "    im_width = IM_WIDTH\n",
    "    im_height = IM_HEIGHT\n",
    "    front_camera = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = carla.Client(\"localhost\", 2000)\n",
    "        self.client.set.timeout(2.0)\n",
    "        self.world = self.client.get_world()\n",
    "        self.blueprint_library = self.world.get_blueprint_library()\n",
    "        self.model3 = self.blueprint_library.filter(\"model3\")[0]\n",
    "        \n",
    "    def reset(self):\n",
    "        self.collision_hist = []\n",
    "        self.actor_list = []\n",
    "        \n",
    "        self.transform = random.choice(self.world.get_map().get_spawn_points())\n",
    "        self.vehicle = self.world.spawn_actor(self.model3, self.transform)\n",
    "        self.actor_list.append(self.vehicle)\n",
    "        \n",
    "        self.rgb_cam = self.blueprint_library.find('sensor.camera.rgb')\n",
    "        self.rgb_cam.set_attribute(\"image_size_x\", f\"{self.im_width}\")\n",
    "        self.rgb_cam.set_attribute(\"image_size_y\", f\"{self.im_height}\")\n",
    "        self.rgb_cam.set_attribute(\"fov\", f\"110\")\n",
    "        \n",
    "        transform = carla.Transform(carla.Location(x=2.5, z=0.7))\n",
    "        self.sensor = self.world.spawn_actor(self.rgb_cam, transform, attach_to=self.vehicle)\n",
    "        self.actor_list.append(self.sensor)\n",
    "        self.sensor.listen(lambda data: self.process_img(data))\n",
    "        \n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle=0.0, brake=0.0))\n",
    "        time.sleep(4)\n",
    "        \n",
    "        colsensor = self.blueprint_library.find(\"sensor.other.collision\")\n",
    "        self.colsensor = self.world.spawn_actor(colsensor, transform, attach_to=self.vehicle)\n",
    "        self.actor_list.append(self.colsensor)\n",
    "        self.colsensor.listen(lambda event: self.collision_data(event))\n",
    "        \n",
    "        while self.front_camera is None:\n",
    "            time.sleep(0.01)\n",
    "            \n",
    "        self.episode_start = time.time()\n",
    "        \n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle=0.0, brake=0.0))\n",
    "        \n",
    "        return self.front_camera\n",
    "    \n",
    "    def collision_data(self, event):\n",
    "        self.collision_hist.append(event)\n",
    "        \n",
    "    def process_img(self, image):\n",
    "        i = np.array(image.raw_data)\n",
    "        i2 = i.reshape((self.im_height, self.im_width, 4))\n",
    "        i3 = i2[:, :, :3]\n",
    "        if self.SHOW_CAM:\n",
    "            cv2.imshow(\"image\", np.array(i3, dtype = np.uint8))\n",
    "            cv2.waitKey(0)  \n",
    "            cv2.destroyAllWindows()\n",
    "        self.front_camera = i3\n",
    "        \n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=-1*self.STEER_AMT))\n",
    "        elif action == 1:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=0))\n",
    "        elif action == 2:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=1*self.STEER_AMT))\n",
    "            \n",
    "        v = self.vehicle.get_velocity()\n",
    "        kmh = int(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2))\n",
    "        \n",
    "        if len(self.collision_hist) != 0:\n",
    "            done = True\n",
    "            reward = -200\n",
    "        elif kmh < 50:\n",
    "            done = False\n",
    "            reward = -1\n",
    "        else:\n",
    "            done = False\n",
    "            reward = 1\n",
    "            \n",
    "        if self.episode_start + SECONDS_PER_EPISODE < time.time():\n",
    "            done = True\n",
    "            \n",
    "        return self.front_camera, reward, done, None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        self.model = self.create_model()\n",
    "        self.target_model = self.create_model()\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        \n",
    "        self.replay_memory = deque(maxlen=REPLAY_MEMORY_SIZE)\n",
    "        \n",
    "        self.tensorboard = ModifiedTensorBoard(log_dir=f\"logs/{MODEL_NAME}-{int(time.time())}\")\n",
    "        self.target_update_counter = 0\n",
    "        self.graph = tf.compat.v1.get_default_graph()\n",
    "        \n",
    "        self.terminate = False\n",
    "        self.last_logged_episode = 0\n",
    "        self.training_initialized = False\n",
    "        \n",
    "    def create_model(self):\n",
    "        base_model = Xception(weights=None, include_top=False, input_shape=(IM_HEIGHT, IM_WIDTH, 3))\n",
    "        \n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        \n",
    "        predictions = Dense(3, activation=\"linear\")(x)\n",
    "        model = Model(inputs = base_model.input, outputs = predictions)\n",
    "        model.compile(loss=\"mse\", optimizer=Adam(lr=0.001), metrics=[\"accuracy\"])\n",
    "        return model\n",
    "    \n",
    "    def update_replay_memory(self, transition):\n",
    "        # transition = (current_state, action, reward, new_state, done)\n",
    "        self.replay_memory.append(transition)\n",
    "        \n",
    "    def train(self):\n",
    "        if len(self.replay_memory) < MIN_REPLAY_MEMORY_SIZE:\n",
    "            return\n",
    "        \n",
    "        minibatch = random.sample(self.replay_memory, MINIBATCH_SIZE)\n",
    "        \n",
    "        current_states = np.array([transition[0] for transition in minibatch])/255\n",
    "        with self.graph.as_default():\n",
    "            current_qs_list = self.model.predict(current_states, PREDICTION_BATCH_SIZE)\n",
    "            \n",
    "        new_current_states = np.array([transition[3] for transition in minibatch])/255\n",
    "        with self.graph.as_default():\n",
    "            future_qs_list = self.target_model.predict(new_current_states, PREDICTION_BATCH_SIZE)\n",
    "            \n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        for index, (current_state, action, reward, new_state, done) in enumerate(minibatch):\n",
    "            if not done:\n",
    "                max_future_q = np.max(future_qs_list[index])\n",
    "                new_q = reward + DISCOUNT * max_future_q\n",
    "            else:\n",
    "                new_q = reward\n",
    "                \n",
    "            current_qs = current_qs_list[index]\n",
    "            current_qs[action] = new_q\n",
    "\n",
    "            X.append(current_state)\n",
    "            y.append(current_qs)\n",
    "        \n",
    "        log_this_step = False\n",
    "        if self.tensorboard.step > self.last_logged_episode:\n",
    "            log_this_step = True\n",
    "            self.last_logged_episode = self.tensorboard.step\n",
    "            \n",
    "        with self.graph.as_default():\n",
    "            self.model.fit(np.array(X)/255, np.array(y), batch_size=TRAINING_BATCH_SIZE, verbose=0, shuffle=False, callbacks=[self.tensorboard] if log_this_step else None)\n",
    "            \n",
    "        if log_this_step:\n",
    "            self.target_update_counter += 1\n",
    "            \n",
    "        if self.target_update_counter > UPDATE_TARGET_EVERY:\n",
    "            self.target_model.set_weights(self.model.get_weights())\n",
    "            self.target_update_counter = 0\n",
    "            \n",
    "    def get_qs(self, state):\n",
    "        return self.model.predict(np.array(state).reshape(-1, *state.shape)/255)[0]\n",
    "    \n",
    "    def train_in_loop(self):\n",
    "        X = np.random.uniform(size = (1, IM_HEIGHT, IM_WIDTH, 3)).astype(np.float32)\n",
    "        y = np.random.uniform(size = (1, 3)).astype(np.float32)\n",
    "        with self.graph.as_default():\n",
    "            self.model.fit(X, y, verbose=False, batch_size=1)\n",
    "            \n",
    "        self.training_initialized = True\n",
    "        \n",
    "        while True:\n",
    "            if self.terminate:\n",
    "                return\n",
    "            self.train()\n",
    "            time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-31685308ad04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQNAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtrainer_thread\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_in_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a8401c445441>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREPLAY_MEMORY_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModifiedTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"logs/{MODEL_NAME}-{int(time.time())}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_update_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9746f49db81a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Overriding this method to stop creating default log writer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'contrib'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    FPS = 20\n",
    "    ep_rewards = [-200]\n",
    "    \n",
    "    random.seed(1)\n",
    "    np.random.seed(1)\n",
    "    tf.compat.v1.set_random_seed(1)\n",
    "    \n",
    "    gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=MEMORY_FRACTION)\n",
    "    tf.compat.v1.keras.backend.set_session(\n",
    "        tf.compat.v1.Session(\n",
    "            config=tf.compat.v1.ConfigProto(gpu_options=gpu_options)))\n",
    "    \n",
    "    if not os.path.isdir(\"models\"):\n",
    "        os.makedirs(\"models\")\n",
    "        \n",
    "    agent = DQNAgent()\n",
    "    \n",
    "    trainer_thread = Thread(target=agent.train_in_loop, daemon=True)\n",
    "    trainer_thread.start()\n",
    "    \n",
    "    while not agent.training_initialized:\n",
    "        time.sleep(0.01)\n",
    "    \n",
    "    agent.get_qs(np.ones((env.im_height, env.im_width, 3)))\n",
    "    \n",
    "    for episode in tqdm(range(1, EPISODES+1), unit=\"episodes\"):\n",
    "        env.collision_hist = []\n",
    "        agent.tensorboard.step = episode\n",
    "        episode_reward = 0\n",
    "        step = 1\n",
    "        current_state = env.reset()\n",
    "        done = False\n",
    "        episode_start = time.time()\n",
    "        \n",
    "        while True:\n",
    "            if np.random.random() > epsilon:\n",
    "                action = np.argmax(agent.get_qs(current_state))\n",
    "            else:\n",
    "                action = np.random.randint(0, 3)\n",
    "                time.sleep(1/FPS)\n",
    "                \n",
    "            new_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            episode_reward += reward\n",
    "            \n",
    "            agent.update_replay_memory((current_state, action, reward, new_state, done))\n",
    "            \n",
    "            step += 1\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        for actor in env.actor_list:\n",
    "            actor.destroy()\n",
    "            \n",
    "        # Append episode reward to a list and log stats (every given number of episodes)\n",
    "        ep_rewards.append(episode_reward)\n",
    "        if not episode % AGGREGATE_STATS_EVERY or episode == 1:\n",
    "            average_reward = sum(ep_rewards[-AGGREGATE_STATS_EVERY:])/len(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "            min_reward = min(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "            max_reward = max(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "            agent.tensorboard.update_stats(reward_avg=average_reward, reward_min=min_reward, reward_max=max_reward, epsilon=epsilon)\n",
    "\n",
    "            # Save model, but only when min reward is greater or equal a set value\n",
    "            if min_reward >= MIN_REWARD:\n",
    "                agent.model.save(f'models/{MODEL_NAME}__{max_reward:_>7.2f}max_{average_reward:_>7.2f}avg_{min_reward:_>7.2f}min__{int(time.time())}.model')\n",
    "\n",
    "        # Decay epsilon\n",
    "        if epsilon > MIN_EPSILON:\n",
    "            epsilon *= EPSILON_DECAY\n",
    "            epsilon = max(MIN_EPSILON, epsilon)\n",
    "            \n",
    "    # Set termination flag for training thread and wait for it to finish\n",
    "    agent.terminate = True\n",
    "    trainer_thread.join()\n",
    "    agent.model.save(f'models/{MODEL_NAME}__{max_reward:_>7.2f}max_{average_reward:_>7.2f}avg_{min_reward:_>7.2f}min__{int(time.time())}.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
