{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/songyang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n",
      "/Users/songyang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "\n",
    "# t_c are temperatures in Celsius\n",
    "t_c = torch.tensor([0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0])\n",
    "# t_u are the unknown units\n",
    "t_u = torch.tensor([35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4])\n",
    "# Add the extra dimension at axis 1\n",
    "t_c = torch.tensor(t_c).unsqueeze(1) \n",
    "t_u = torch.tensor(t_u).unsqueeze(1) \n",
    "\n",
    "# separate training and validation data\n",
    "n_samples = t_u.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "train_t_u = t_u[train_indices]\n",
    "train_t_c = t_c[train_indices]\n",
    "\n",
    "val_t_u = t_u[val_indices]\n",
    "val_t_c = t_c[val_indices]\n",
    "\n",
    "class SubclassModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_linear = nn.Linear(1, 13)\n",
    "        self.output_linear = nn.Linear(13, 1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        hidden_t = self.hidden_linear(input)\n",
    "        activated_t = torch.tanh(hidden_t)\n",
    "        output_t = self.output_linear(activated_t)\n",
    "        \n",
    "        return output_t\n",
    "    \n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_t_u, val_t_u, train_t_c, val_t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # forward propagation and calculate loss\n",
    "        train_t_p = model(train_t_u) \n",
    "        train_loss = loss_fn(train_t_p, train_t_c)\n",
    "        \n",
    "        # all requires_grad args are forced to False inside this block\n",
    "        with torch.no_grad(): \n",
    "            val_t_p = model(val_t_u)\n",
    "            val_loss = loss_fn(val_t_p, val_t_c)\n",
    "            assert val_loss.requires_grad == False \n",
    "                \n",
    "        # This could be done at any point in the loop prior to calling loss.backward()\n",
    "        optimizer.zero_grad()\n",
    "        # back propagation\n",
    "        train_loss.backward()\n",
    "        # gradient descent\n",
    "        optimizer.step()\n",
    "\n",
    "        # logging\n",
    "        if epoch <= 3 or epoch % 500 == 0:\n",
    "            print('Epoch {}, Training loss {}, Validation loss {}'.format(\n",
    "                epoch, float(train_loss), float(val_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 159.493896484375, Validation loss 301.6928405761719\n",
      "Epoch 2, Training loss 157.00473022460938, Validation loss 296.9797668457031\n",
      "Epoch 3, Training loss 154.5560760498047, Validation loss 292.30792236328125\n",
      "Epoch 500, Training loss 9.453768730163574, Validation loss 4.634730815887451\n",
      "Epoch 1000, Training loss 2.915877342224121, Validation loss 6.790077209472656\n",
      "Epoch 1500, Training loss 1.636523962020874, Validation loss 10.700006484985352\n",
      "Epoch 2000, Training loss 1.47880220413208, Validation loss 18.23255157470703\n",
      "Epoch 2500, Training loss 1.4053064584732056, Validation loss 12.723899841308594\n",
      "Epoch 3000, Training loss 1.3663643598556519, Validation loss 8.851823806762695\n",
      "Epoch 3500, Training loss 1.3228051662445068, Validation loss 7.098437786102295\n",
      "Epoch 4000, Training loss 1.2599670886993408, Validation loss 6.0246262550354\n",
      "Epoch 4500, Training loss 1.2378054857254028, Validation loss 6.077049732208252\n",
      "Epoch 5000, Training loss 1.2277344465255737, Validation loss 6.24127721786499\n"
     ]
    }
   ],
   "source": [
    "subclass_model = SubclassModel()\n",
    "optimizer = optim.Adam(subclass_model.parameters(), lr=1e-2) \n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 5000, \n",
    "    optimizer = optimizer,\n",
    "    model = subclass_model, \n",
    "    loss_fn = nn.MSELoss(),\n",
    "    train_t_u = train_t_u, \n",
    "    val_t_u = val_t_u, \n",
    "    train_t_c = train_t_c,\n",
    "    val_t_c = val_t_c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16.1833],\n",
       "        [22.5342]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subclass_model(val_t_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13.],\n",
       "        [21.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_t_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.5497],\n",
       "        [-0.7100],\n",
       "        [-0.0995],\n",
       "        [ 0.8792],\n",
       "        [ 0.8614],\n",
       "        [-0.8993],\n",
       "        [ 0.4741],\n",
       "        [-0.7448],\n",
       "        [-0.8313],\n",
       "        [-0.1044],\n",
       "        [ 0.9547],\n",
       "        [-0.8931],\n",
       "        [-0.1994]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subclass_model.hidden_linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.3794, -0.1218,  6.6280,  0.8143,  0.5835, -0.6513, -0.6846, -0.8382,\n",
       "         0.5822,  5.3046,  0.9968,  0.6348,  4.2853], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subclass_model.hidden_linear.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000],\n",
       "        [0.0000],\n",
       "        [0.0298],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0531],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0161]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subclass_model.hidden_linear.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.7466, -0.9554, -7.0336,  1.0472,  0.5834, -0.8309,  0.7443, -0.7942,\n",
       "         -0.8668, -6.6206,  0.8292, -0.9431, -5.7018]], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subclass_model.output_linear.weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
